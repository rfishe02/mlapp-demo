{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model for our application\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, get_cosine_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "import pathlib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a497b4a7fe246336\n",
      "Found cached dataset csv (/Users/renaef/.cache/huggingface/datasets/csv/default-a497b4a7fe246336/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b392357cd97c4e539282e59a91f6982a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/renaef/.cache/huggingface/datasets/csv/default-a497b4a7fe246336/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-60ed97895a9cb5f3.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/renaef/.cache/huggingface/datasets/csv/default-a497b4a7fe246336/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-14a16ae9c8240c30.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 269\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"./data/spotify_millsongdata.csv\")['train']\n",
    "dataset = dataset.filter(lambda example: 'abba' in example[\"artist\"].lower())\n",
    "dataset = dataset.remove_columns([\"artist\", \"song\", \"link\"])\n",
    "dataset = dataset.shuffle(seed=123)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 242\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 27\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = dataset.train_test_split(test_size=0.1)\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429e2652ffb141dbaf58e3f1facea272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6906cc2f9647108d23ef6f7b1cd11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5943ab6c0aa645239a31dfdbd98f179c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba925bc8c964e929570c4d71312438a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2', cache_dir=pathlib.Path('cache').resolve())\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True, num_proc=1, remove_columns=[\"text\"])\n",
    "block_size = tokenizer.model_max_length\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renaef/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 97\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 52\n",
      "  Number of trainable parameters = 124439808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e270384e81e3435b9ca13b4024dcc336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4212, 'learning_rate': 9.292589525111794e-05, 'epoch': 0.38}\n",
      "{'loss': 2.6389, 'learning_rate': 1.725216267546246e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d30cb7b7a74e9482f25f405c4f4a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/checkpoint-13\n",
      "Configuration saved in output/checkpoint-13/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2880771160125732, 'eval_runtime': 9.4581, 'eval_samples_per_second': 1.057, 'eval_steps_per_second': 0.211, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/checkpoint-13/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5624, 'learning_rate': 7.857716640189785e-06, 'epoch': 1.15}\n",
      "{'loss': 2.4878, 'learning_rate': 7.686881626551516e-05, 'epoch': 1.54}\n",
      "{'loss': 2.3779, 'learning_rate': 0.00013520660867542716, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cdea1b2c4344f39e6bff3e7f4066aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/checkpoint-26\n",
      "Configuration saved in output/checkpoint-26/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.011009693145752, 'eval_runtime': 9.1364, 'eval_samples_per_second': 1.095, 'eval_steps_per_second': 0.219, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/checkpoint-26/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0717, 'learning_rate': 0.00010756924162575734, 'epoch': 2.31}\n",
      "{'loss': 1.9569, 'learning_rate': 2.9630758374242683e-05, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ca968484d3444ea903468102bc1de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/checkpoint-39\n",
      "Configuration saved in output/checkpoint-39/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8960673809051514, 'eval_runtime': 9.3112, 'eval_samples_per_second': 1.074, 'eval_steps_per_second': 0.215, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/checkpoint-39/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9482, 'learning_rate': 1.9933913245728396e-06, 'epoch': 3.08}\n",
      "{'loss': 1.9393, 'learning_rate': 6.033118373448485e-05, 'epoch': 3.46}\n",
      "{'loss': 1.8375, 'learning_rate': 0.00012934228335981018, 'epoch': 3.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c6aaa195ba451e8a8b7b591ccf8722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/checkpoint-52\n",
      "Configuration saved in output/checkpoint-52/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8812570571899414, 'eval_runtime': 9.1952, 'eval_samples_per_second': 1.088, 'eval_steps_per_second': 0.218, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in output/checkpoint-52/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from output/checkpoint-52 (score: 1.8812570571899414).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2272.3501, 'train_samples_per_second': 0.171, 'train_steps_per_second': 0.023, 'train_loss': 2.3043749240728526, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23502b3ec7b4a128ba507a233a0df54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = \"output\"\n",
    "seed = 123\n",
    "LEARNING_RATE = 1.372e-4\n",
    "num_train_epochs = 4\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_total_limit=10,\n",
    "    save_strategy='epoch',\n",
    "    save_steps=1,\n",
    "    report_to=None,\n",
    "    seed=seed,\n",
    "    logging_steps=5,\n",
    "    do_eval=True,\n",
    "    eval_steps=1,\n",
    "    load_best_model_at_end=True\n",
    "    # disable_tqdm=True\n",
    "    # load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    # tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"]\n",
    ")\n",
    "\n",
    "train_dataloader = trainer.get_train_dataloader()\n",
    "num_train_steps = len(train_dataloader)\n",
    "trainer.create_optimizer_and_scheduler(num_train_steps)\n",
    "trainer.lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    trainer.optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_train_steps\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "evaluation = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['You be careful of him you\\'re gonna think you\\'re gonna save me, I\\'ll burn the sun, and I\\'ll fight you, baby boy!\"\\n  \\r\\nThat\\'s what I think\\n  \\r\\nDangerous things are always like that  \\r\\nDangerous things are always like that  \\r\\nDon\\'t get fooled by fools  \\r\\n  \\r\\nOh, but it ain\\'t gonna happen  \\r\\nWell then I just wanna take my chances, then  \\r\\nYeah, yeah.  \\r\\n  \\r\\nHey hey don\\'t touch me  \\r\\n  \\r\\nDon\\'t touch me girl  \\r\\nDon\\'t touch me girl girl  \\r\\nDon\\'t touch me girl',\n",
       " \"You was running late for a run, I think she said something funny and so I thought something funny. The feeling I had is gone now, I think. I took her by the hand, smiled in front of her eyes and told her you were right. I'm so proud of you I'm almost crying. I'll never forget the feeling I had. It's so wrong and I want you to know I'm proud of you, I am.  \\r\\nIn the face of all the power, in the face of death, in a blind alley, it's all a dream.  \\r\\nWalking through the streets of New York, I was so lucky.  \\r\\n  \\r\\nWhen the street lights turned on, I was in my late forties\",\n",
       " 'You can say that a good thing can\\'t happen at such a young age\" (Sang)  \\r\\nI just want to live my life, get my education, get better, get married, I don\\'t understand it.  \\r\\nIt\\'s the feeling that a lot of people are missing.  \\r\\nIt\\'s what\\'s really frightening and strange.  \\r\\n \\r\\nThe girl with the blue-eyed smile had just given birth, to a boy who couldn\\'t help but stare at her.  \\r\\n  \\r\\nShe told me a story that a girl had told in a cafe called Imelda (Imelda)  \\r\\nI was there when the bell rang at eleven o\\'clock and I was told to',\n",
       " 'You can find me in any street of a city, I\\'ve had my share of fame\", and \"I\\'m not your new friend so you\\'ll never hear me again until you\\'re dead\" - they\\'re the songs I\\'ve been singing ever since I was a baby and they\\'ll never come true.\\n\\nListen to me, I\\'m on the verge of dying  \\r\\nI\\'m in a hurry I\\'m making my way through the jungle  \\r\\nI\\'m getting the hang of it all  \\r\\nI\\'m feeling bad I\\'m on the edge  \\r\\nI\\'m never going anywhere  \\r\\nI\\'ve got enough in the bank of money  \\r\\nA million dollars to buy this girl  \\r\\nAnd tonight she\\'s gonna take me',\n",
       " 'You don\\'t know your own child!\"\\n\"It\\'s really a nice feeling just sitting through a movie  \\r\\nWith the kids  \\r\\nI could make you feel safe  \\r\\nYou\\'d better not get your hands on a doll  \\r\\n  \\r\\nCrazy baby  \\r\\n  \\r\\nWhat\\'s your name  \\r\\nYou\\'re a stranger  \\r\\nDon\\'t know what\\'s funny, what\\'s not funny  \\r\\n  \\r\\nTelling a lot, never making any mistakes, not looking for love  \\r\\n  \\r\\nDon\\'t feel guilty for losing your soul  \\r\\nI love you and I\\'m not going to fight  \\r\\nI think it\\'s funny that',\n",
       " \"You can play it safe' when it's done and the game is over, then go get another set of headphones.  \\r\\nToukyū  \\r\\nWalking on the streets of Japan has to be a kind of fun affair for me right?  \\r\\nWell, when you're living in such a place where it's cold, you'll be having to walk for hours like someone could walk out for hours  \\r\\nIt's sad, because I've played before  \\r\\n  \\r\\nI've played  \\r\\n  \\r\\nIn the night, when I don't hear a man's name and I'm not sure what I can do  \\r\\nThe man's going to come, I don't know what to\",\n",
       " \"You know that I'm pretty good here too - oh I can feel it's getting a little rough around the house I must have done something wrong you'd think - well - my girl said yes, but it's just an overabundance of misery - no I'm just too lonely in here - we should go have a laugh - yeah, it's gonna be funny when you're with me - yeah -  \\r\\nCaught up in the act of living the life of another woman - all I've done is walk away from her - just don't call it love I'm still not sure  \\r\\n  \\r\\nNever the kind - I've got no intention of ending it all - it's just too late to start -\",\n",
       " \"You-so-so  \\r\\nI was born when my father died I took your love seriously I'll always find your peace I know what to do  \\r\\nBut I was never too sure  \\r\\n  \\r\\nI love you  \\r\\nNever too tired to cry  \\r\\n  \\r\\nAnd love you still  \\r\\nAnd you love me  \\r\\n  \\r\\nLove your master, but still feel the pain  \\r\\nLove is only a tool  \\r\\n  \\r\\nI'll keep my promises  \\r\\n Promise me no more will it please  \\r\\n  \\r\\nIt will always be so, never give me less  \\r\\nCocaine is poison,\",\n",
       " 'You don\\'t go through that again, baby!\" She said softly.\\n\\n\"Just sit and see! You\\'re getting your head up and I\\'m going to let you go, no baby!\"\\n\\nShe said with a sneer, but you wouldn\\'t know it until you\\'re talking to me now, you are going to tell me all I need to know!\\n\\nYour last laugh was just like your last cry, but now you feel so cold and you\\'re burning inside, it hurts to know you\\'re falling, it\\'s as hard as it seems!\\n\\nBut it\\'s your last kiss, and I don\\'t think I can take it, so I leave, and I try to kiss you again.\\n\\nI kissed you again to kiss another woman, the one I',\n",
       " 'You\\'re like me, but with you so much stronger, I\\'ll help you get to the point I want to be.\"\\nThe smile was so strong when he said, \"I know you\\'ve been working hard lately, but it\\'s not working anymore, you\\'re losing it, you\\'re really lonely, I think it\\'s time for something better.\"\\nHe couldn\\'t stop crying when he said, \"I know it\\'s too late, I\\'ll come tomorrow and get back to the place I was supposed to go in  \\r\\nThe morning lights went down in the dark, just as I told you  \\r\\nHe had walked in his dream for hours before he started to wonder  \\r\\n \\r\\n\\'Cause we had been married for five years already\\'']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = \"You\"\n",
    "num_sequences =  10\n",
    "min_length =  100\n",
    "max_length =   160\n",
    "temperature = 1\n",
    "top_p = 0.95\n",
    "top_k = 50\n",
    "repetition_penalty =  1.0\n",
    "\n",
    "encoded_prompt = tokenizer(start, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "encoded_prompt = encoded_prompt.to(trainer.model.device)\n",
    "\n",
    "# prediction\n",
    "output_sequences = trainer.model.generate(\n",
    "    input_ids=encoded_prompt,\n",
    "    max_length=max_length,\n",
    "    min_length=min_length,\n",
    "    temperature=float(temperature),\n",
    "    top_p=float(top_p),\n",
    "    top_k=int(top_k),\n",
    "    do_sample=True,\n",
    "    repetition_penalty=repetition_penalty,\n",
    "    num_return_sequences=num_sequences)\n",
    "\n",
    "def post_process(output_sequences):\n",
    "    generated_sequences = []\n",
    "\n",
    "    max_repeat = 2\n",
    "\n",
    "    # decode prediction\n",
    "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "        generated_sequence = generated_sequence.tolist()\n",
    "        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
    "        generated_sequences.append(text.strip())\n",
    "                    \n",
    "    return generated_sequences\n",
    "\n",
    "post_process(output_sequences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "- Chapter 7: Deep Learning for Text, Deep Learning in Python by François Chollet\n",
    "- GPT-2, Accessed at: https://huggingface.co/gpt2\n",
    "- OpenAPI GPT-2, Accessed at: https://huggingface.co/docs/transformers/main/en/model_doc/gpt2\n",
    "- Fine-tune a pretrained model, Accessed at: https://huggingface.co/docs/transformers/training#train-in-native-pytorch\n",
    "- HuggingArtists - Train a model to generate lyrics, Accessed at: https://colab.research.google.com/github/AlekseyKorshuk/huggingartists/blob/master/huggingartists-demo.ipynb\n",
    "- HuggingTweets - Train a model to generate tweets, Accessed at: https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb\n",
    "- Spotify Million Song Dataset, Accessed at: https://www.kaggle.com/datasets/notshrirang/spotify-million-song-dataset\n",
    "- Datasets, Accessed at: https://huggingface.co/docs/datasets/index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6859d0864aa76b03f74600b56e94b6efc7264cc44842d33771427805dad0a134"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
